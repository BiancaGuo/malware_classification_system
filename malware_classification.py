import hashlib
import os
import re
import time
import pickle
from keras.preprocessing.sequence import pad_sequences
import malware_classification_by_static_feature.get_ngram as ngram
import numpy as np

from sklearn.externals import joblib
from tensorflow.contrib import learn
from keras.models import load_model
from malware_classification_by_dynamic_feature import get_api_sequence


def match(file_path,Bytes=1024):
    '''
    求文件md5值
    :param file_path:
    :param Bytes:
    :return:
    '''
    md5_1 = hashlib.md5()
    with open(file_path,'rb') as f:
        while 1:
            data =f.read(Bytes)
            if data:
                md5_1.update(data)
            else:
                break
    ret = md5_1.hexdigest()
    return ret



def get_example_filenames_from_dir(data_dir, max_length, is_line_as_word=False):
    examples = []
    if not os.path.isdir(data_dir):
        return examples
    for fname in os.listdir(data_dir):
        if fname=="APIs.txt":
            full_path = os.path.join(data_dir, fname)
            f = open(full_path, "r")
            data = f.read()
            line_num = len(data.split("\n"))
            new_lines = []
            for line in data.split("\n"):
                if not line.startswith("#"):
                    new_lines.append(line)
            data = "\n".join(new_lines)
            if line_num < 5:
                continue
            if not is_line_as_word:
                examples.append(data.strip())
            else:
                lines = data.split("\n")
                # replace each line as md5
                words = [hashlib.md5(line.encode("utf-8")).hexdigest() for line in lines]
                examples.append(" ".join(words[:max_length]))
            f.close()
    return examples


def get_document_length_limit(dir_name):
    p = re.compile('sen_len=(\d+)')
    m = p.search(dir_name)
    if m:
        return int(m.group(1))
    else:
        return None

def getOpcodeSequence(filename):
    opcode_seq = []
    p = re.compile(r'[\s]{16}([a-z]+)$|[\s]{16}([a-z]+[\s]{2})')
    with open(filename,encoding='utf-8') as f:
        f=list(f)
        for i in range(0,len(f)):
            if str(f[i]).strip()=="; Segment type: Pure code":
                for j in range(i+1,len(f)):
                    if re.match(r"; Segment type:*",str(f[j]).strip()) or j==len(f)-1:
                        i=j
                        break
                    m = re.findall(p,str(f[j]))
                    # print(str(f[j]))
                    if m:
                        # print(m)
                        opc = str(m[0][1]).strip()
                        opc2 = str(m[0][0]).strip()
                        if opc!='' and opc != "align" and opc != "db":
                            opcode_seq.append(opc)
                        elif opc2!='' and opc2 != "align" and opc2 != "db":
                            opcode_seq.append(opc2)
            # if flag==1:
            #     break

    return opcode_seq

def static_predict(filepath):
    '''
       根据静态特征进行类别预测
       '''
    # filepath = "D:\\bat\\adwares\\test\\038cbe00178254638c76635798498f15"
    # filename = match(filepath)
    # filename = ".\\tmp\\" + filename + ".txt"
    command = 'D:\\IDA7.0\\idat.exe -B ' + filepath
    os.system(command)
    opcode_sequence = getOpcodeSequence(filepath + ".asm")
    op3gram = ngram.getOpcodeNgram(opcode_sequence)  # 获得ngram组
    selected_static_features = ngram.getStaticFeatures()
    standard = {}
    for feature in selected_static_features:  # str
        temp = feature.replace('(', '').replace(')', '').replace('\'', '')
        feature_tuple = tuple([str(i).strip() for i in temp.split(',')])
        if feature_tuple in op3gram:
            standard[feature_tuple] = op3gram[feature_tuple]
        else:
            standard[feature_tuple] = 0

    file_selected_static_feature_list = []
    file_list = []
    for num in standard.values():
        file_selected_static_feature_list.append(num)

    key_list = {}
    # key_list["Name"] = []
    # key_list["Malware"] = []
    key_list["Magic"] = 0
    key_list["MajorLinkerVersion"] = 0
    key_list["MinorLinkerVersion"] = 0
    key_list["SizeOfCode"] = 0
    key_list["SizeOfInitializedData"] = 0
    key_list["SizeOfUninitializedData"] = 0
    key_list["AddressOfEntryPoint"] = 0
    key_list["BaseOfCode"] = 0
    key_list["BaseOfData"] = 0
    key_list["ImageBase"] = 0
    key_list["SectionAlignment"] = 0
    key_list["FileAlignment"] = 0
    key_list["MajorOSystemVersion"] = 0
    key_list["MinorOSystemVersion"] = 0
    key_list["MajorImageVersion"] = 0
    key_list["MinorImageVersion"] = 0
    key_list["MajorSubsystemVersion"] = 0
    key_list["MinorSubsystemVersion"] = 0
    key_list["Win32Version"] = 0
    key_list["SizeOfImage"] = 0
    key_list["SizeOfHeaders"] = 0
    key_list["CheckSum"] = 0
    key_list["Subsystem"] = 0
    key_list["DllCharacteristics"] = 0
    key_list["SizeOfStackReserve"] = 0
    key_list["SizeOfStackCommit"] = 0
    key_list["SizeOfHeapReserve"] = 0
    key_list["SizeOfHeapCommit"] = 0
    key_list["LoaderFlags"] = 0
    key_list["NumberOfRvaAndSizes"] = 0
    # key_list["Name"].append(os.path.basename(filepath) + ".txt")
    # key_list["Malware"].append(1)
    # 存储出现的头信息的名称
    exit_key_list = []
    # exit_key_list.append("Name")
    # exit_key_list.append("Malware")

    command = 'objdump -x ' + filepath
    header_info = os.popen(command).read().strip()
    p = r'.*\n'
    header_info = re.findall(p, header_info)
    for i in range(0, len(header_info)):
        if re.match(r'Magic*', str(header_info[i]).strip('\n')):
            for j in range(i, i + 30):
                if str(header_info[j]).strip('\n') == "":
                    break
                s = str(header_info[j]).strip('\n')
                s = s.split("\t")
                key = [x.strip() for x in s if x.strip() != ''][0]
                value = [x.strip() for x in s if x.strip() != ''][1]
                exit_key_list.append(key)
                if key == "MajorLinkerVersion" or key == "MinorLinkerVersion" or key == "MajorOSystemVersion" or key == "MinorOSystemVersion" or key == "MajorImageVersion" or key == "MinorImageVersion" or key == "MajorSubsystemVersion" or key == "MinorSubsystemVersion":
                    key_list[key] = int(value)
                else:
                    key_list[key] = int(value, 16)
            break
    for num in key_list.values():
        file_selected_static_feature_list.append(num)
    file_list.append(file_selected_static_feature_list)
    rf_model = joblib.load('mix_rf_model.pkl')  # 选择模型
    static_feature_result = rf_model.predict(file_list)

    return static_feature_result[0]



def dynamic_predict(filepath):
    command = 'cuckoo submit ' + filepath
    cuckoo_command = os.popen(command).read()
    cuckoo_num = str(cuckoo_command).split('#')[1].strip('\n')
    print(cuckoo_num)
    cuckoo_log_path = "C:\\Users\\47892\\.cuckoo\\storage\\analyses\\" + cuckoo_num + "\\reports\\report.json"
    while True:
        if os.path.exists(cuckoo_log_path):
            time.sleep(30)
            API_sequence = get_api_sequence.extract_api_sequence_from_one_file(cuckoo_log_path)
            break

    maxlen = 2000
    # deep learning
    tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))
    x_test_word_ids = tokenizer.texts_to_sequences(API_sequence)
    x_test_padded_seqs = pad_sequences(x_test_word_ids, maxlen=maxlen)
    model = load_model("model_weight_train_cnn_4.h5")
    y_pred = model.predict(x_test_padded_seqs)
    meta_train = np.zeros(shape=(len(API_sequence), 7))
    meta_train[:] = y_pred
    predict_type_list = []
    for l in y_pred:
        l_tmp = l.tolist()
        predict_type = l_tmp.index(max(l_tmp))
        predict_type_list.append(predict_type)
    return predict_type_list[0]

if __name__ == "__main__":

    '''
    根据静态特征进行类别预测
    '''
    filepath=".\\upload\\0a28b556b4b6998265fa9fe649554533"
    filename=match(filepath)
    filename=".\\tmp\\"+filename + ".txt"
    command = 'D:\\IDA7.0\\idat.exe -B ' + filepath
    os.system(command)
    opcode_sequence=getOpcodeSequence(filepath+".asm")
    op3gram = ngram.getOpcodeNgram(opcode_sequence)  # 获得ngram组
    selected_static_features=ngram.getStaticFeatures()
    standard = {}
    for feature in selected_static_features:#str
        temp = feature.replace('(', '').replace(')', '').replace('\'', '')
        feature_tuple = tuple([str(i).strip() for i in temp.split(',')])
        if feature_tuple in op3gram:
            standard[feature_tuple] = op3gram[feature_tuple]
        else:
            standard[feature_tuple] = 0

    file_selected_static_feature_list=[]
    file_list=[]
    for num in standard.values():
        file_selected_static_feature_list.append(num)

    key_list = {}
    # key_list["Name"] = []
    # key_list["Malware"] = []
    key_list["Magic"] = 0
    key_list["MajorLinkerVersion"] = 0
    key_list["MinorLinkerVersion"] = 0
    key_list["SizeOfCode"] = 0
    key_list["SizeOfInitializedData"] = 0
    key_list["SizeOfUninitializedData"] = 0
    key_list["AddressOfEntryPoint"] = 0
    key_list["BaseOfCode"] = 0
    key_list["BaseOfData"] = 0
    key_list["ImageBase"] = 0
    key_list["SectionAlignment"] = 0
    key_list["FileAlignment"] = 0
    key_list["MajorOSystemVersion"] = 0
    key_list["MinorOSystemVersion"] = 0
    key_list["MajorImageVersion"] = 0
    key_list["MinorImageVersion"] = 0
    key_list["MajorSubsystemVersion"] = 0
    key_list["MinorSubsystemVersion"] = 0
    key_list["Win32Version"] = 0
    key_list["SizeOfImage"] = 0
    key_list["SizeOfHeaders"] = 0
    key_list["CheckSum"] = 0
    key_list["Subsystem"] = 0
    key_list["DllCharacteristics"] = 0
    key_list["SizeOfStackReserve"] = 0
    key_list["SizeOfStackCommit"] = 0
    key_list["SizeOfHeapReserve"] = 0
    key_list["SizeOfHeapCommit"] = 0
    key_list["LoaderFlags"] = 0
    key_list["NumberOfRvaAndSizes"] = 0
    # key_list["Name"].append(os.path.basename(filepath) + ".txt")
    # key_list["Malware"].append(1)
    # 存储出现的头信息的名称
    exit_key_list = []
    # exit_key_list.append("Name")
    # exit_key_list.append("Malware")

    command = 'objdump -x ' + filepath
    header_info = os.popen(command).read().strip()
    p = r'.*\n'
    header_info = re.findall(p, header_info)
    for i in range(0, len(header_info)):
        if re.match(r'Magic*', str(header_info[i]).strip('\n')):
            for j in range(i, i + 30):
                if str(header_info[j]).strip('\n') == "":
                    break
                s = str(header_info[j]).strip('\n')
                s = s.split("\t")
                key = [x.strip() for x in s if x.strip() != ''][0]
                value = [x.strip() for x in s if x.strip() != ''][1]
                exit_key_list.append(key)
                if key == "MajorLinkerVersion" or key == "MinorLinkerVersion" or key == "MajorOSystemVersion" or key == "MinorOSystemVersion" or key == "MajorImageVersion" or key == "MinorImageVersion" or key == "MajorSubsystemVersion" or key == "MinorSubsystemVersion":
                    key_list[key]=int(value)
                else:
                    key_list[key]=int(value, 16)
            break
    for num in key_list.values():
        file_selected_static_feature_list.append(num)
    file_list.append(file_selected_static_feature_list)
    rf_model = joblib.load('mix_rf_model.pkl')#选择模型
    static_feature_result=rf_model.predict(file_list)
    print(static_feature_result)#静态预测结果

    '''
    根据动态特征进行结果预测
    '''
    # command = 'cuckoo submit ' + filepath
    # cuckoo_command = os.popen(command).read()
    # cuckoo_num=str(cuckoo_command).split('#')[1].strip('\n')
    # print(cuckoo_num)
    # cuckoo_log_path="C:\\Users\\47892\\.cuckoo\\storage\\analyses\\"+cuckoo_num+"\\reports\\report.json"
    # while True:
    #     if os.path.exists(cuckoo_log_path):
    #         time.sleep(30)
    #         API_sequence=get_api_sequence.extract_api_sequence_from_one_file(cuckoo_log_path)
    #         break
    #
    # maxlen=2000
    # # deep learning
    # tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))
    # x_test_word_ids = tokenizer.texts_to_sequences(API_sequence)
    # x_test_padded_seqs = pad_sequences(x_test_word_ids, maxlen=maxlen)
    # model = load_model("model_weight_train_cnn_4.h5")
    # y_pred = model.predict(x_test_padded_seqs)
    # meta_train = np.zeros(shape=(len(API_sequence), 7))
    # meta_train[:] = y_pred
    # predict_type_list = []
    # for l in y_pred:
    #     l_tmp = l.tolist()
    #     predict_type = l_tmp.index(max(l_tmp))
    #     predict_type_list.append(predict_type)
    # print(predict_type_list[0])