import pickle
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
import time
import csv
import xgboost as xgb
import numpy as np
from sklearn.model_selection import StratifiedKFold
from model_test import plot_matrix
from sklearn import metrics

'''
XGBoost是boosting算法的其中一种。Boosting算法的思想是将许多弱分类器集成在一起形成一个强分类器。因为XGBoost是一种提升树模型，所以它是将许多树模型集成在一起，形成一个很强的分类器。而所用到的树模型则是CART回归树模型。
'''


with open("cnn_and_lstm_result.pkl", "rb") as f:
    cnn_lstm_train_result = pickle.load(f)

# with open("tfidf_result.pkl", "rb") as f:
#     tfidf_train_result = pickle.load(f)

with open("cnn_result.pkl", "rb") as f:
    cnn_train_result = pickle.load(f)

with open("lstm_result.pkl", "rb") as f:
    lstm_train_result = pickle.load(f)
	
with open("dynamic_feature_test.csv.pkl", "rb") as f:
    labels = pickle.load(f)
    # files = pickle.load(f)

# train = np.hstack([tfidf_train_result, cnn_train_result, cnn_lstm_train_result,lstm_train_result])
# test = np.hstack([tfidf_out_result, cnn_out_result, lstm_out_result, cnn_lstm_out_result])
train = np.hstack([cnn_train_result, cnn_lstm_train_result,lstm_train_result])

skf = StratifiedKFold(n_splits=5, random_state=4, shuffle=True)
# dout = xgb.DMatrix(test)
ac = 0
pe = 0
re = 0
f = 0
for i, (tr_ind, te_ind) in enumerate(skf.split(train, labels)):
    print('FOLD: {}'.format(str(i)))
    X_train, y_train_label = train[tr_ind], np.array(labels)[tr_ind]
    X_val, y_val_label = train[te_ind], np.array(labels)[te_ind]
    dtrain = xgb.DMatrix(X_train, label=y_train_label)
    dtest = xgb.DMatrix(X_val, y_val_label)  # label可以不要，此处需要是为了测试效果

    param = {'max_depth': 6, 'eta': 0.01, 'eval_metric': 'mlogloss', 'silent': True, 'objective': 'multi:softprob',
             'num_class': 8, 'subsample': 0.9,
             'colsample_bytree': 0.85}  # 参数
    evallist = [(dtrain, 'train'), (dtest, 'val')]  # 测试 , (dtrain, 'train')
    num_round = 100  # 循环次数
    bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=20,verbose_eval=False)
    bst.save_model('mix_' + str(i) + '.model')
#     y_pred = bst.predict(dtest)
#
#     predict_type_list = []
#     for l in y_pred:
#         l_tmp = l.tolist()
#         predict_type = l_tmp.index(max(l_tmp))
#         predict_type_list.append(predict_type)
#     # 准确率
#     accuracy = metrics.accuracy_score(y_val_label, predict_type_list)
#     print("准确率： " + str(accuracy))
#     ac += accuracy
#     # 精确率
#     precision = metrics.precision_score(y_val_label, predict_type_list, average='macro')
#     print("精确率： " + str(precision))
#     pe += precision
#     # 召回率
#     recall = metrics.recall_score(y_val_label, predict_type_list, average='macro')
#     print("召回率： " + str(recall))
#     re += recall
#     # F1-score
#     f1 = metrics.f1_score(y_val_label, predict_type_list, average='weighted')
#     print("F1-score： " + str(f1))
#     f += f1
#     # 混淆矩阵
#     plot_matrix("mix_" + str(i), y_val_label, predict_type_list)
#
# print("平均：")
# print("准确率： " + str(ac / 5))
# print("精确率： " + str(pe / 5))
# print("召回率： " + str(re / 5))
# print("F1-score： " + str(f / 5))